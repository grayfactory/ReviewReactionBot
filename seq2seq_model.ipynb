{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNh3LJg2kvMF",
        "outputId": "49c54349-54ee-486f-86ef-93de69bbe406"
      },
      "source": [
        "!pip install soynlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soynlp\n",
            "  Downloading soynlp-0.0.493-py3-none-any.whl (416 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 61 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 81 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 92 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 102 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 112 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 122 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 133 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 143 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 153 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 163 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 174 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 184 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 194 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 204 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 215 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 225 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 235 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 245 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 256 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 266 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 276 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 286 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 296 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 307 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 317 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 327 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 337 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 348 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 358 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 368 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 378 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 389 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 399 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 409 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 416 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.4.1)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.0.1)\n",
            "Installing collected packages: soynlp\n",
            "Successfully installed soynlp-0.0.493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvpiH6YPUsK4",
        "outputId": "ad4a5a78-c0f0-4179-f382-2d5dbb8023d5"
      },
      "source": [
        "!git clone https://github.com/grayfactory/ReviwReactionBot.git\n",
        "%cd ReviwReactionBot/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ReviwReactionBot'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 25 (delta 6), reused 23 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (25/25), done.\n",
            "/content/ReviwReactionBot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noLnjmhFS6XF",
        "outputId": "8527a3fb-3d88-4041-e26d-30eb8e6b6081"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xApUUI1hU8HT",
        "outputId": "6c9f1834-13ff-40cf-ee5d-97d2012cf4d6"
      },
      "source": [
        "# simbolic link\n",
        "!ln -s /content/gdrive/My\\ Drive/chat_bot/ReviewReactionBot /chat_bot\n",
        "!ls /chat_bot"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoints\tpreprocessing.ipynb  Seq2Seq_model.py\n",
            "data\t\tpreprocessing.py     Seq2Seq_Transformer.ipynb\n",
            "df_save.pkl\t__pycache__\t     small_transformer.png\n",
            "lightning_logs\tREADME.md\t     soynlp_word_extractor.pkl\n",
            "model_chp\trequirements.txt     train_koGPT2.py\n",
            "preprocessing\tReviewReactionBot    visualize.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmABv-npV8jZ"
      },
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# custom functions\n",
        "from Seq2Seq_model import transformer, CustomSchedule, loss_function\n",
        "from preprocessing import pre_processing_text"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajUv1cdoVzX0"
      },
      "source": [
        "class MyConfig(dict):\n",
        "  def __getattr__(self, name): return self[name]\n",
        "  def __setattr__(self, name, value): self[name] = value\n",
        "\n",
        "def get_data_csv_path(configs, condition):\n",
        "  condition = condition\n",
        "  return [f for f in configs.data_list if f'{condition}' in str(f)][0]\n",
        "\n",
        "configs = MyConfig({\n",
        "    'path_drive': Path('/chat_bot'), \n",
        "    'vocab_size': 32000, # hyperparameter same as koGTP2\n",
        "    'MAX_LENGTH': 128 # hyperparameter same as koGTP2\n",
        "})\n",
        "\n",
        "configs.data_list = [f for f in (configs.path_drive / 'data').glob('*')]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "c8z885sMWC9x",
        "outputId": "6362a62a-f0d1-4f2c-9dba-92c413fb6e5d"
      },
      "source": [
        "df = pd.read_csv(get_data_csv_path(configs,'ChatbotData_v2.csv'))\n",
        "df = df.dropna()\n",
        "df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>star_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>와 진짜 대박 맛있 어서 암청 많이 먹다가 리뷰 하는거 까먹어서 지금 남기네요 ㄷㄷ...</td>\n",
              "      <td>맛있 게 드셨다니 저희 도 정말 기쁩니다 ㅎㅎ 더 맛있 고 정성 스럽게 조리 할테니...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13</td>\n",
              "      <td>치킨 이 양이 적어 보이는데 치킨 덩어리 가 엄청 커요!! 목덕후인 저는 목이 없어...</td>\n",
              "      <td>소중한 사진 리뷰 감사 합니다 ! 앞으로 도 더 맛있 는 음식 으로 찾아 뵐게요 ~...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14</td>\n",
              "      <td>처음 시켜 보는데 상담히 만족 합니다. 배달 주문 하기 힘드신 어머님 이 부탁 하셔...</td>\n",
              "      <td>첫 주문 에 만족 하셨다니 정말 다행이에요 ㅎㅎ 앞으로 도 초심 잃지 않고 저희 모...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15</td>\n",
              "      <td>맛있 게 잘 먹었습니다</td>\n",
              "      <td>소중한 리뷰 감사 합니다 ! 더 맛있 고 정성 스러운 음식 으로 찾아 뵐게요 좋은 ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>맛있 었어요. 감사 합니다.</td>\n",
              "      <td>맛있 게 드셨다니 정말 다행이에요 감사 합니다 ! 좋은 하루 보내 시고 항상 건강 ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... star_avg\n",
              "0          12  ...      5.0\n",
              "1          13  ...      4.0\n",
              "2          14  ...      5.0\n",
              "3          15  ...      5.0\n",
              "4          16  ...      5.0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FSgznki-DL0"
      },
      "source": [
        "# 1. Tokenized with tensorflow SubwordTextEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw48dI1U-BjL",
        "outputId": "44d5ed4e-2352-4b21-b9bf-bc04b6724ea0"
      },
      "source": [
        "text_list = [text for text in df.Q.to_list() + df.A.to_list() if text] # if None False\n",
        "len(text_list)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1145822"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSiNEWKi-K_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a8df7e8-6bb6-413b-ddb4-22ab2a8f4d9b"
      },
      "source": [
        "%%time\n",
        "# tf 서브워드텍스트인코더를 사용하여 [질문, 답변] 데이터로부터 단어 집합(Vocabulary) 생성\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    text_list, target_vocab_size=configs.vocab_size)\n",
        "\n",
        "# 시작 토큰과 종료 토큰에 대한 정수 부여(vocav size의 마지막 두 숫자). \n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7min 22s, sys: 1.23 s, total: 7min 23s\n",
            "Wall time: 7min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkjO3JjHArhT",
        "outputId": "a814d200-2a11-4e47-d21b-7f63bccc016d"
      },
      "source": [
        "# tokenizer 작동 확인\n",
        "print(f'Vocab size:{tokenizer.vocab_size}')\n",
        "# 임으의 문장 encodign test\n",
        "print(tokenizer.encode(text_list[20]))\n",
        "print(tokenizer.encode('이 집 짬뽕 맛있네요.'))\n",
        "for ts in tokenizer.encode('이 집 짬뽕 맛있네요.'):\n",
        "  print(f'{ts} -- {tokenizer.decode([ts])}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size:32190\n",
            "[284, 271, 794, 2551, 306, 8, 2118, 21, 48, 79, 223, 1524, 599, 2808, 284, 2118, 164, 58, 11, 18, 572, 25349]\n",
            "[10, 665, 3801, 4252, 31980]\n",
            "10 -- 이 \n",
            "665 -- 집 \n",
            "3801 -- 짬뽕 \n",
            "4252 -- 맛있네요\n",
            "31980 -- .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZS4Eq1kBjX7",
        "outputId": "4a72d99c-7402-4bb4-c128-9644cd6c2665"
      },
      "source": [
        "# train data, sentence pair Tokenizing\n",
        "\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenize_inputs, tokenize_outputs = [], []\n",
        "\n",
        "  for (sent1, sent2) in zip(inputs, outputs):\n",
        "\n",
        "    sent1 = START_TOKEN + tokenizer.encode(sent1) + END_TOKEN\n",
        "    sent2 = START_TOKEN + tokenizer.encode(sent2) + END_TOKEN\n",
        "\n",
        "    tokenize_inputs.append(sent1)\n",
        "    tokenize_outputs.append(sent2)\n",
        "\n",
        "  # padding\n",
        "  tokenize_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenize_inputs, maxlen=configs.MAX_LENGTH, padding='post'\n",
        "  )\n",
        "  tokenize_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenize_outputs, maxlen=configs.MAX_LENGTH, padding='post'\n",
        "  )\n",
        "\n",
        "  return tokenize_inputs, tokenize_outputs\n",
        "\n",
        "review_encode, answer_encode = tokenize_and_filter( df['Q'], df['A'] )\n",
        "\n",
        "# 최종 학습 데이터 pair\n",
        "print(review_encode.shape, answer_encode.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(572911, 128) (572911, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdScMe_xB9Rc"
      },
      "source": [
        "# 2. Training Transformer model\n",
        "### Data batch 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdQPSsYuCBA_"
      },
      "source": [
        "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
        "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
        "configs.BATCH_SIZE = 128 \n",
        "configs.BUFFER_SIZE = 20000 # 버퍼에 올릴 데이터 size & shuffle\n",
        "\n",
        "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': review_encode,\n",
        "        'dec_inputs': answer_encode[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
        "    },\n",
        "    {   # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. # 교사 강요을 위한 output(정답)\n",
        "        'outputs': answer_encode[:, 1:] \n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(configs.BUFFER_SIZE)\n",
        "dataset = dataset.batch(configs.BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78EvtZ1BELwb"
      },
      "source": [
        "# Hyper-parameters\n",
        "configs.D_MODEL = 256\n",
        "configs.NUM_LAYERS = 2\n",
        "configs.NUM_HEADS = 8\n",
        "configs.DFF = 512\n",
        "configs.DROPOUT = 0.1\n",
        "configs.VOCAB_SIZE = VOCAB_SIZE\n",
        "configs.EPOCHS = 5\n",
        "\n",
        "configs.learning_rate = CustomSchedule(configs.D_MODEL)\n",
        "\n",
        "configs.optimizer = tf.keras.optimizers.Adam(\n",
        "    configs.learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC9oOLrvE8Lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3322bf18-3059-4c80-f92e-3c0fba1e7fe0"
      },
      "source": [
        "configs"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BATCH_SIZE': 128,\n",
              " 'BUFFER_SIZE': 20000,\n",
              " 'DFF': 512,\n",
              " 'DROPOUT': 0.1,\n",
              " 'D_MODEL': 256,\n",
              " 'EPOCHS': 5,\n",
              " 'MAX_LENGTH': 128,\n",
              " 'NUM_HEADS': 8,\n",
              " 'NUM_LAYERS': 2,\n",
              " 'VOCAB_SIZE': 32192,\n",
              " 'data_list': [PosixPath('/chat_bot/data/df_강남구_세곡동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_강남구_개포동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_강남구_자곡동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_송파구_송파1동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_송파구_송파2동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_송파구_석촌동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_송파구_문정1동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_송파구_문정2동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_송파구_오륜동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_송파구_오금동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_종로구_사직동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_종로구_삼청동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_종로구_부암동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_강남구_청담동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_종로구_평창동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_강남구_삼성동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_종로구_무악동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_강남구_논현동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_강남구_수서동 (1).pkl'),\n",
              "  PosixPath('/chat_bot/data/df_종로구_이화동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_종로구_창신1동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_종로구_창신2동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_종로구_혜화동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_강남구_수서동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_강남구_대치동.pkl'),\n",
              "  PosixPath('/chat_bot/data/df_강남구_신사동.pkl'),\n",
              "  PosixPath('/chat_bot/data/ChatbotData_small.csv'),\n",
              "  PosixPath('/chat_bot/data/ChatbotData.csv'),\n",
              "  PosixPath('/chat_bot/data/ChatbotData_v2.csv')],\n",
              " 'learning_rate': <Seq2Seq_model.CustomSchedule at 0x7fb8fa08c610>,\n",
              " 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam at 0x7fb8e3715410>,\n",
              " 'path_drive': PosixPath('/chat_bot'),\n",
              " 'vocab_size': 32000}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5eB9By8FCsf"
      },
      "source": [
        "# check-points\n",
        "configs.checkpoint_path = str(configs.path_drive / 'checkpoints' / 'cp-{epoch:04d}.ckpt')\n",
        "# \"/content/gdrive/MyDrive/chat_bot/ReviewReactionBot/checkpoints/cp-{epoch:04d}.ckpt\"\n",
        "# checkpoint_dir = os.path.dirname(checkpoint_path)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOMxZH3TB6lh",
        "outputId": "928d196f-3331-4422-b152-992eb2afb1a7"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=configs.VOCAB_SIZE,\n",
        "    num_layers=configs.NUM_LAYERS,\n",
        "    dff=configs.DFF,\n",
        "    d_model=configs.D_MODEL,\n",
        "    num_heads=configs.NUM_HEADS,\n",
        "    dropout=configs.DROPOUT)\n",
        "\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, configs.MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=configs.optimizer, loss=loss_function, metrics=[accuracy])\n",
        "\n",
        "\n",
        "# 모델의 가중치를 저장하는 콜백 만들기\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=configs.checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    verbose=1\n",
        "    # period= # 만약 1 epoch씩 저장하지 않으면\n",
        "    )\n",
        "\n",
        "# `checkpoint_path` 포맷을 사용하는 가중치를 저장합니다\n",
        "model.save_weights(configs.checkpoint_path.format(epoch=0))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 32192, 256)\n",
            "(1, 32192, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHe6YbGlGWvI"
      },
      "source": [
        "model.fit(dataset, \n",
        "          epochs=configs.EPOCHS,\n",
        "          callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2bMjl-Kjhjm"
      },
      "source": [
        "# 최종 모델 Checkpoint load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTTKuwIEjhBm",
        "outputId": "3d9637b9-6250-4204-959b-8b8e24b8b191"
      },
      "source": [
        "# 최종 checkpoint load\n",
        "latest = tf.train.latest_checkpoint('/chat_bot/checkpoints/')\n",
        "print(latest)\n",
        "\n",
        "# 새로운 model 객체\n",
        "model = transformer(\n",
        "    vocab_size=configs.VOCAB_SIZE,\n",
        "    num_layers=configs.NUM_LAYERS,\n",
        "    dff=configs.DFF,\n",
        "    d_model=configs.D_MODEL,\n",
        "    num_heads=configs.NUM_HEADS,\n",
        "    dropout=configs.DROPOUT)\n",
        "\n",
        "model.compile(optimizer=configs.optimizer, loss=loss_function, metrics=[accuracy])\n",
        "model.load_weights(latest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/chat_bot/checkpoints/cp-0010.ckpt\n",
            "(1, 31974, 256)\n",
            "(1, 31974, 256)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa934df95d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-u7dZOykoHo",
        "outputId": "340d485f-0571-46b9-a6a7-6a384be68823"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  sentence = pre_processing_text(sentence)\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 예측 시작\n",
        "  for i in range(configs.MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
        "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence\n",
        "\n",
        "output = predict('이 집 짬뽕 진짜 맛있네요!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 이 집 짬뽕 진짜 맛있네요!\n",
            "Output: 안녕하세요 논현 스쿨푸드입니다. 배달도 빠르고 맛있다니 최고의 칭찬입니다. 항상 노력하는 논현 스쿨푸드를 사랑해주세요.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JOta5_7lBf4",
        "outputId": "83c0dbc3-295c-40fa-ec52-85074c93a29d"
      },
      "source": [
        "new_sentence = ['이 집 짱뽕 진짜 맛있네요',\n",
        "                '음식이 다 식어서 왔어여,,, ㅠㅠ',\n",
        "                '공짜로 줘도 다시는 안먹는다ㅎㅎㅎㅎㅎ',\n",
        "                '공짜로 줘도 다시는 안먹는다.',\n",
        "                'ㄷㄷㄷㄷ']\n",
        "\n",
        "for text in new_sentence:\n",
        "  predict(text)\n",
        "  print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 이 집 짱뽕 진짜 맛있네요\n",
            "Output: 자주 이용해 주시고 소중한 리뷰 주셔서 감사드립니다. 항상 맛있게 드셔주신다는 말씀에 앞으로도 변함없이 행복한 맛을 느끼시도록 최선을 다하여 준비하겠습니다. 웃음 넘치는 하루 보내시길 바랍니다.\n",
            "\n",
            "\n",
            "Input: 음식이 다 식어서 왔어여,,, ㅠㅠ\n",
            "Output: 사랑하는 고객님, 저희 음식을 주문해주셔서 감사합니다 배달이 지연되어 죄송합니다 ㅠㅠ 맛있는 음식 빠르게 받으실수있도록 노력하겠습니다. 오늘하루도 건강하고 행복한하루되세요~ （╹◡╹）\n",
            "\n",
            "\n",
            "Input: 공짜로 줘도 다시는 안먹는다ㅎㅎㅎㅎㅎ\n",
            "Output: 맛있게 드셔주셔서 정말 감사합니다~~!! 저희 기본 소스 자체에 매콤한맛이 조금 조금 조금 덜 맵게 해달라고 요청사항에 적어주시면 잘 준비해드리겠습니다!!\n",
            "\n",
            "\n",
            "Input: 공짜로 줘도 다시는 안먹는다.\n",
            "Output: 맛있게 드셔주셔서 정말 감사합니다~~!! 저희 기본 소스 자체에 매콤한맛이 조금 조금 조금 덜 맵게 해달라고 요청사항에 적어주시면 잘 준비해드리겠습니다!!\n",
            "\n",
            "\n",
            "Input: ㄷㄷㄷㄷ\n",
            "Output: 소중한 리뷰 감사드립니다♡ 언제나 감동을 드릴 수 있는 맛과 서비스로 보답해드리겠습니다! 앞으로도 저희 명도찜닭 많은 이용 부탁드립니다 건강 조심하시고, 다음에 또 주문주세요~!\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}